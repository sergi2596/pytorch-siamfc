C:\Users\Sergi\tfg\pytorch-siamfc\training-example (master -> origin)
Î» python main.py -a alexnet --lr 0.01 --pretrained --evaluate D:\TFG\ILSVRC\Data\VID
=> using pre-trained model 'alexnet'
C:\Users\Sergi\AppData\Local\Programs\Python\Python37\lib\site-packages\torchvision\transforms\transforms.py:562: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.
  warnings.warn("The use of the transforms.RandomSizedCrop transform is deprecated, " +
C:\Users\Sergi\AppData\Local\Programs\Python\Python37\lib\site-packages\torchvision\transforms\transforms.py:187: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.
  warnings.warn("The use of the transforms.Scale transform is deprecated, " +
main.py:221: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  input_var = torch.autograd.Variable(input, volatile=True)
main.py:222: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  target_var = torch.autograd.Variable(target, volatile=True)
main.py:230: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
main.py:231: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  top1.update(prec1[0], input.size(0))
main.py:232: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  top5.update(prec5[0], input.size(0))
Test: [0/688]   Time 25.820 (25.820)    Loss 14.6759 (14.6759)  Prec@1 0.000 (0.000)    Prec@5 0.000 (0.000)
Test: [10/688]  Time 3.546 (4.873)      Loss 6.6343 (12.7960)   Prec@1 0.000 (0.000)    Prec@5 1.172 (0.107)
Test: [20/688]  Time 0.172 (3.877)      Loss 20.1203 (13.1662)  Prec@1 0.000 (0.000)    Prec@5 1.562 (0.130)
Test: [30/688]  Time 4.369 (3.474)      Loss 13.6949 (12.4377)  Prec@1 0.000 (0.176)    Prec@5 0.000 (1.714)
Test: [40/688]  Time 0.956 (3.005)      Loss 18.3650 (13.0161)  Prec@1 0.000 (0.133)    Prec@5 0.000 (1.296)
Test: [50/688]  Time 3.962 (2.881)      Loss 11.7642 (13.0966)  Prec@1 0.000 (0.107)    Prec@5 0.000 (1.042)
Test: [60/688]  Time 3.179 (2.714)      Loss 17.9193 (12.9213)  Prec@1 0.000 (0.115)    Prec@5 0.000 (0.935)
Test: [70/688]  Time 5.288 (2.740)      Loss 11.5232 (13.2804)  Prec@1 0.000 (0.099)    Prec@5 0.000 (0.803)
Test: [80/688]  Time 6.661 (2.694)      Loss 9.9803 (13.0040)   Prec@1 0.000 (0.227)    Prec@5 0.000 (1.273)
Test: [90/688]  Time 1.003 (2.701)      Loss 8.9834 (12.7148)   Prec@1 0.000 (0.202)    Prec@5 0.000 (1.133)
Test: [100/688] Time 5.245 (2.780)      Loss 13.8736 (12.6276)  Prec@1 0.000 (0.182)    Prec@5 0.000 (1.021)
Test: [110/688] Time 4.660 (2.811)      Loss 13.6659 (12.7145)  Prec@1 0.000 (0.165)    Prec@5 0.000 (0.929)
Test: [120/688] Time 4.809 (2.933)      Loss 11.9140 (12.7514)  Prec@1 0.000 (0.152)    Prec@5 0.000 (0.852)
Test: [130/688] Time 2.491 (2.981)      Loss 12.9479 (12.5965)  Prec@1 0.000 (0.140)    Prec@5 0.000 (0.856)
Test: [140/688] Time 2.474 (2.985)      Loss 10.9135 (12.7473)  Prec@1 0.000 (0.130)    Prec@5 0.000 (0.795)
Test: [150/688] Time 1.911 (3.015)      Loss 11.5045 (12.5796)  Prec@1 0.000 (0.122)    Prec@5 0.000 (0.748)
Test: [160/688] Time 2.912 (3.001)      Loss 15.5045 (12.5010)  Prec@1 0.000 (0.124)    Prec@5 0.000 (0.757)
Test: [170/688] Time 3.069 (3.054)      Loss 8.8280 (12.3391)   Prec@1 0.000 (0.117)    Prec@5 0.000 (0.713)
Test: [180/688] Time 2.279 (3.093)      Loss 10.5066 (12.1871)  Prec@1 0.000 (0.110)    Prec@5 0.000 (0.673)
Test: [190/688] Time 2.805 (3.069)      Loss 4.9817 (12.1225)   Prec@1 2.734 (0.119)    Prec@5 37.109 (0.832)
Test: [200/688] Time 5.190 (3.071)      Loss 7.8553 (12.0137)   Prec@1 0.000 (0.113)    Prec@5 0.000 (0.805)
Test: [210/688] Time 3.312 (3.084)      Loss 10.6107 (11.9522)  Prec@1 0.391 (0.109)    Prec@5 1.172 (0.779)
Test: [220/688] Time 2.506 (3.053)      Loss 7.3289 (11.8332)   Prec@1 0.000 (0.104)    Prec@5 0.000 (0.778)
Test: [230/688] Time 0.652 (2.987)      Loss 11.2477 (11.6189)  Prec@1 0.000 (0.101)    Prec@5 0.000 (0.896)
Test: [240/688] Time 3.107 (3.013)      Loss 10.4355 (11.7668)  Prec@1 0.000 (0.097)    Prec@5 0.000 (0.859)
Test: [250/688] Time 0.165 (2.956)      Loss 11.8790 (11.6780)  Prec@1 0.000 (0.093)    Prec@5 0.000 (0.826)
Test: [260/688] Time 7.643 (2.990)      Loss 10.1698 (11.7293)  Prec@1 0.000 (0.090)    Prec@5 0.000 (0.795)
Test: [270/688] Time 2.447 (2.993)      Loss 9.2664 (11.6332)   Prec@1 0.000 (0.088)    Prec@5 0.000 (0.768)
Test: [280/688] Time 2.913 (3.010)      Loss 10.1915 (11.5375)  Prec@1 0.000 (0.085)    Prec@5 0.000 (0.766)
Test: [290/688] Time 3.038 (3.032)      Loss 13.3159 (11.5676)  Prec@1 0.000 (0.082)    Prec@5 0.000 (0.740)
Test: [300/688] Time 2.432 (3.043)      Loss 13.4657 (11.6082)  Prec@1 0.000 (0.079)    Prec@5 0.000 (0.715)
Test: [310/688] Time 0.197 (3.011)      Loss 13.7616 (11.6789)  Prec@1 0.000 (0.077)    Prec@5 0.000 (0.703)
Test: [320/688] Time 2.385 (3.022)      Loss 11.5365 (11.7569)  Prec@1 0.000 (0.074)    Prec@5 0.000 (0.681)
Test: [330/688] Time 0.170 (2.988)      Loss 7.9072 (11.8150)   Prec@1 0.000 (0.072)    Prec@5 0.000 (0.661)
Test: [340/688] Time 0.141 (2.979)      Loss 12.8234 (11.8347)  Prec@1 0.000 (0.077)    Prec@5 0.000 (0.663)
Test: [350/688] Time 3.318 (2.983)      Loss 6.4269 (11.7883)   Prec@1 0.000 (0.075)    Prec@5 0.391 (0.645)
Test: [360/688] Time 5.398 (3.022)      Loss 6.1870 (11.6313)   Prec@1 0.000 (0.306)    Prec@5 1.172 (1.115)
Test: [370/688] Time 3.429 (3.003)      Loss 9.3950 (11.5868)   Prec@1 0.000 (0.298)    Prec@5 0.000 (1.084)
Test: [380/688] Time 1.728 (3.037)      Loss 15.0710 (11.6513)  Prec@1 0.000 (0.296)    Prec@5 0.000 (1.082)
Test: [390/688] Time 2.628 (3.048)      Loss 6.3515 (11.5971)   Prec@1 0.000 (0.289)    Prec@5 0.000 (1.054)
Test: [400/688] Time 2.393 (3.051)      Loss 9.5830 (11.6312)   Prec@1 0.000 (0.282)    Prec@5 0.000 (1.033)
Test: [410/688] Time 8.717 (3.032)      Loss 7.7470 (11.6233)   Prec@1 0.000 (0.275)    Prec@5 0.000 (1.007)
Test: [420/688] Time 0.167 (3.014)      Loss 19.2869 (11.6086)  Prec@1 0.000 (0.268)    Prec@5 0.000 (0.999)
Test: [430/688] Time 9.742 (3.020)      Loss 10.5617 (11.7272)  Prec@1 0.000 (0.262)    Prec@5 1.953 (0.981)
Test: [440/688] Time 3.987 (3.023)      Loss 18.2441 (11.8276)  Prec@1 0.000 (0.258)    Prec@5 0.000 (0.965)
Test: [450/688] Time 5.295 (3.025)      Loss 11.9100 (11.8751)  Prec@1 0.000 (0.252)    Prec@5 0.000 (0.944)
Test: [460/688] Time 1.320 (3.005)      Loss 13.6888 (11.8485)  Prec@1 0.000 (0.247)    Prec@5 0.000 (0.924)
Test: [470/688] Time 3.906 (3.009)      Loss 13.8956 (11.8665)  Prec@1 0.000 (0.241)    Prec@5 0.000 (0.904)
Test: [480/688] Time 9.957 (3.010)      Loss 8.1285 (11.8383)   Prec@1 0.000 (0.236)    Prec@5 0.000 (0.885)
Test: [490/688] Time 0.168 (3.015)      Loss 12.2041 (11.8948)  Prec@1 0.000 (0.232)    Prec@5 0.000 (0.867)
Test: [500/688] Time 4.994 (3.045)      Loss 16.5483 (11.9851)  Prec@1 0.000 (0.227)    Prec@5 0.000 (0.850)
Test: [510/688] Time 0.959 (3.048)      Loss 12.7282 (12.0389)  Prec@1 0.000 (0.222)    Prec@5 0.000 (0.833)
Test: [520/688] Time 3.751 (3.024)      Loss 10.8211 (12.0115)  Prec@1 0.000 (0.218)    Prec@5 0.000 (0.817)
Test: [530/688] Time 0.166 (3.034)      Loss 11.3859 (11.9681)  Prec@1 0.000 (0.214)    Prec@5 0.000 (0.803)
Test: [540/688] Time 0.162 (3.017)      Loss 9.5619 (11.9799)   Prec@1 0.000 (0.210)    Prec@5 0.000 (0.788)
Test: [550/688] Time 1.185 (2.990)      Loss 15.3280 (11.9333)  Prec@1 0.000 (0.213)    Prec@5 0.000 (0.803)
Test: [560/688] Time 1.005 (2.977)      Loss 13.0974 (11.9583)  Prec@1 0.000 (0.210)    Prec@5 0.000 (0.792)
Test: [570/688] Time 0.166 (2.982)      Loss 13.4768 (12.0015)  Prec@1 0.000 (0.207)    Prec@5 0.000 (0.779)
Test: [580/688] Time 6.523 (2.980)      Loss 17.2837 (11.9966)  Prec@1 0.000 (0.203)    Prec@5 0.000 (0.765)
Test: [590/688] Time 0.174 (3.005)      Loss 8.0508 (11.9899)   Prec@1 0.000 (0.200)    Prec@5 0.000 (0.753)
Test: [600/688] Time 4.850 (3.016)      Loss 11.1616 (12.0080)  Prec@1 0.000 (0.196)    Prec@5 0.000 (0.741)
Test: [610/688] Time 1.970 (3.018)      Loss 8.9585 (11.9722)   Prec@1 0.000 (0.193)    Prec@5 0.000 (0.729)
Test: [620/688] Time 4.388 (3.039)      Loss 7.5833 (11.9936)   Prec@1 0.000 (0.190)    Prec@5 0.000 (0.717)
Test: [630/688] Time 8.817 (3.041)      Loss 11.4498 (11.9260)  Prec@1 0.000 (0.187)    Prec@5 0.000 (0.712)
Test: [640/688] Time 4.389 (3.057)      Loss 12.9105 (11.9346)  Prec@1 0.000 (0.184)    Prec@5 0.000 (0.701)
Test: [650/688] Time 1.263 (3.066)      Loss 20.5256 (11.9920)  Prec@1 0.000 (0.181)    Prec@5 0.000 (0.690)
Test: [660/688] Time 5.178 (3.063)      Loss 12.7774 (12.0198)  Prec@1 0.000 (0.178)    Prec@5 0.000 (0.680)
Test: [670/688] Time 1.486 (3.048)      Loss 13.3267 (12.0498)  Prec@1 0.000 (0.176)    Prec@5 0.000 (0.669)
Test: [680/688] Time 2.374 (3.051)      Loss 12.4792 (12.0303)  Prec@1 0.000 (0.174)    Prec@5 0.000 (0.715)
 * Prec@1 0.173 Prec@5 0.708